HF_AUTH_TOKEN = "YOUR HUGGING FACE TOKEN"

# Whisper transcription settings
WHISPER_USE_LOCAL = "true"  # Use local Whisper model
WHISPER_USE_VLLM = "false"  # Use vLLM server for transcription
WHISPER_MODEL = "base"  # OpenAI Whisper model size (tiny, base, small, medium, large)
WHISPER_LANGUAGE = "sv"  # Language code or "auto" for auto-detection
WHISPER_LOCAL_MODEL_NAME = "KBLab/kb-whisper-large"  # HuggingFace model for local processing
WHISPER_LOCAL_MODEL_PATH = ""  # Optional local model file path

# vLLM server settings (only used when WHISPER_USE_VLLM=true)
VLLM_BASE_URL = "http://localhost:8000/v1"  # vLLM server base URL
VLLM_API_KEY = "token-abc123"  # vLLM API key
VLLM_MODEL_NAME = "KBLab/kb-whisper-large"  # Model name on vLLM server
VLLM_MAX_AUDIO_FILESIZE_MB = "25"  # Maximum file size - larger files split into 30-second chunks

# Pyannote settings
PYANNOTE_MODEL = "pyannote/speaker-diarization-3.1"
PYANNOTE_USE_REMOTE = "false"  # Set to "true" to use remote pyannote service
PYANNOTE_REMOTE_URL = "http://localhost:8001"  # URL of remote pyannote server
MIN_SPEAKERS = "1"
MAX_SPEAKERS = "10"

# File upload settings
MAX_FILE_SIZE = "104857600"  # 100MB in bytes
